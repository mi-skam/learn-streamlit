{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30days challeng\n",
    "## Day04\n",
    "\n",
    "We follow this [video](https://www.youtube.com/watch?v=Yk-unX4KnV4) *Data Science Portfolio Project From Scratch | Building a YouTube Data Dashboard with Streamlit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"Nov 12, 2020\" doesn't match format \"%B %d, %Y\", at position 1. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m df_agg \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/Aggregated_Metrics_By_Video.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:,:]\n\u001b[1;32m      2\u001b[0m df_agg\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo title\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo publish time\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComments added\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShares\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDislikes\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLikes\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubscribers lost\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubscribers gained\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRPM(USD)\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPM(USD)\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m viewed\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage view duration\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mViews\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWatch time (hours)\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubscribers\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYour estimated revenue (USD)\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImpressions\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImpressions ctr(\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m df_agg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo publish time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_agg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVideo publish time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_agg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage view duration\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_agg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage view duration\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: datetime\u001b[38;5;241m.\u001b[39mstrptime(x,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      7\u001b[0m df_agg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg_duration_sec\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_agg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage view duration\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msecond \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39mminute\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39mhour\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3600\u001b[39m)\n",
      "File \u001b[0;32m~/Development/mi-skam/learn-streamlit/.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/Development/mi-skam/learn-streamlit/.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/mi-skam/learn-streamlit/.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"Nov 12, 2020\" doesn't match format \"%B %d, %Y\", at position 1. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "df_agg = pd.read_csv('./data/Aggregated_Metrics_By_Video.csv').iloc[1:,:]\n",
    "df_agg.columns = ['Video','Video title','Video publish time','Comments added','Shares','Dislikes','Likes',\n",
    "                      'Subscribers lost','Subscribers gained','RPM(USD)','CPM(USD)','Average % viewed','Average view duration',\n",
    "                      'Views','Watch time (hours)','Subscribers','Your estimated revenue (USD)','Impressions','Impressions ctr(%)']\n",
    "df_agg['Video publish time'] = pd.to_datetime(df_agg['Video publish time'])\n",
    "df_agg['Average view duration'] = df_agg['Average view duration'].apply(lambda x: datetime.strptime(x,'%H:%M:%S'))\n",
    "df_agg['Avg_duration_sec'] = df_agg['Average view duration'].apply(lambda x: x.second + x.minute*60 + x.hour*3600)\n",
    "df_agg['Engagement_ratio'] =  (df_agg['Comments added'] + df_agg['Shares'] +df_agg['Dislikes'] + df_agg['Likes']) /df_agg.Views\n",
    "df_agg['Views / sub gained'] = df_agg['Views'] / df_agg['Subscribers gained']\n",
    "df_agg.sort_values('Video publish time', ascending = False, inplace = True)    \n",
    "df_agg_sub = pd.read_csv('./data/Aggregated_Metrics_By_Country_And_Subscriber_Status.csv')\n",
    "df_comments = pd.read_csv('./data/Aggregated_Metrics_By_Video.csv')\n",
    "df_time = pd.read_csv('./data/Video_Performance_Over_Time.csv')\n",
    "df_time['Date'] = pd.to_datetime(df_time['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>Video title</th>\n",
       "      <th>Video pub­lish time</th>\n",
       "      <th>Com­ments ad­ded</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Dis­likes</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Sub­scribers lost</th>\n",
       "      <th>Sub­scribers gained</th>\n",
       "      <th>RPM (USD)</th>\n",
       "      <th>CPM (USD)</th>\n",
       "      <th>Av­er­age per­cent­age viewed (%)</th>\n",
       "      <th>Av­er­age view dur­a­tion</th>\n",
       "      <th>Views</th>\n",
       "      <th>Watch time (hours)</th>\n",
       "      <th>Sub­scribers</th>\n",
       "      <th>Your es­tim­ated rev­en­ue (USD)</th>\n",
       "      <th>Im­pres­sions</th>\n",
       "      <th>Im­pres­sions click-through rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4OZip0cgOho</td>\n",
       "      <td>How I Would Learn Data Science (If I Had to St...</td>\n",
       "      <td>May 8, 2020</td>\n",
       "      <td>907</td>\n",
       "      <td>9583</td>\n",
       "      <td>942</td>\n",
       "      <td>46903</td>\n",
       "      <td>451</td>\n",
       "      <td>46904</td>\n",
       "      <td>6.353</td>\n",
       "      <td>12.835</td>\n",
       "      <td>36.65</td>\n",
       "      <td>0:03:09</td>\n",
       "      <td>1253559</td>\n",
       "      <td>65850.7042</td>\n",
       "      <td>46453</td>\n",
       "      <td>7959.533</td>\n",
       "      <td>26498799</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78LjdAAw0wA</td>\n",
       "      <td>100K Channel Update + AMA Stream!</td>\n",
       "      <td>Nov 12, 2020</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>2.668</td>\n",
       "      <td>6.259</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0:05:14</td>\n",
       "      <td>2291</td>\n",
       "      <td>200.2966</td>\n",
       "      <td>-3</td>\n",
       "      <td>6.113</td>\n",
       "      <td>188318</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hO_YKK_0Qck</td>\n",
       "      <td>Uber Driver to Machine Learning Engineer in 9 ...</td>\n",
       "      <td>Jul 16, 2020</td>\n",
       "      <td>402</td>\n",
       "      <td>152</td>\n",
       "      <td>15</td>\n",
       "      <td>881</td>\n",
       "      <td>9</td>\n",
       "      <td>198</td>\n",
       "      <td>9.516</td>\n",
       "      <td>11.695</td>\n",
       "      <td>15.12</td>\n",
       "      <td>0:10:21</td>\n",
       "      <td>21350</td>\n",
       "      <td>3687.3387</td>\n",
       "      <td>189</td>\n",
       "      <td>202.963</td>\n",
       "      <td>442334</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uXLnbdHMf8w</td>\n",
       "      <td>Why I'm Starting Data Science Over Again.</td>\n",
       "      <td>Aug 29, 2020</td>\n",
       "      <td>375</td>\n",
       "      <td>367</td>\n",
       "      <td>22</td>\n",
       "      <td>2622</td>\n",
       "      <td>40</td>\n",
       "      <td>1957</td>\n",
       "      <td>3.143</td>\n",
       "      <td>7.943</td>\n",
       "      <td>33.41</td>\n",
       "      <td>0:02:36</td>\n",
       "      <td>49564</td>\n",
       "      <td>2148.3110</td>\n",
       "      <td>1917</td>\n",
       "      <td>155.779</td>\n",
       "      <td>521185</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xgg7dIKys9E</td>\n",
       "      <td>Interview with the Director of AI Research @ N...</td>\n",
       "      <td>Aug 5, 2020</td>\n",
       "      <td>329</td>\n",
       "      <td>118</td>\n",
       "      <td>15</td>\n",
       "      <td>590</td>\n",
       "      <td>11</td>\n",
       "      <td>161</td>\n",
       "      <td>2.973</td>\n",
       "      <td>7.425</td>\n",
       "      <td>9.55</td>\n",
       "      <td>0:04:37</td>\n",
       "      <td>13429</td>\n",
       "      <td>1034.3945</td>\n",
       "      <td>150</td>\n",
       "      <td>39.920</td>\n",
       "      <td>210876</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>FBgs-BSTIJE</td>\n",
       "      <td>Demystifying Data Science Roles</td>\n",
       "      <td>Nov 30, 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5.218</td>\n",
       "      <td>16.232</td>\n",
       "      <td>55.55</td>\n",
       "      <td>0:03:28</td>\n",
       "      <td>978</td>\n",
       "      <td>56.5930</td>\n",
       "      <td>7</td>\n",
       "      <td>5.103</td>\n",
       "      <td>26202</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Yr5T3T4tq-g</td>\n",
       "      <td>Most Data Science Hopefuls Overlook This Impor...</td>\n",
       "      <td>May 25, 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.374</td>\n",
       "      <td>15.596</td>\n",
       "      <td>58.62</td>\n",
       "      <td>0:02:06</td>\n",
       "      <td>548</td>\n",
       "      <td>19.2752</td>\n",
       "      <td>5</td>\n",
       "      <td>1.849</td>\n",
       "      <td>21780</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>j-Z-je6K4Yg</td>\n",
       "      <td>IT'S NOT TOO LATE TO LEARN CODE!</td>\n",
       "      <td>Dec 18, 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.784</td>\n",
       "      <td>12.590</td>\n",
       "      <td>60.52</td>\n",
       "      <td>0:01:52</td>\n",
       "      <td>721</td>\n",
       "      <td>22.5450</td>\n",
       "      <td>7</td>\n",
       "      <td>2.728</td>\n",
       "      <td>18635</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>5jntoZX-Tc8</td>\n",
       "      <td>NASA Physicist Turned Data Scientist (Tim Bowl...</td>\n",
       "      <td>May 5, 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.651</td>\n",
       "      <td>12.206</td>\n",
       "      <td>16.93</td>\n",
       "      <td>0:03:09</td>\n",
       "      <td>1094</td>\n",
       "      <td>57.6363</td>\n",
       "      <td>3</td>\n",
       "      <td>2.900</td>\n",
       "      <td>34642</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>5p73cIRYCZg</td>\n",
       "      <td>ProjectDemoCSC478_UFCFightData</td>\n",
       "      <td>Jun 6, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.79</td>\n",
       "      <td>0:01:04</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>365</td>\n",
       "      <td>11.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Video                                        Video title  \\\n",
       "1    4OZip0cgOho  How I Would Learn Data Science (If I Had to St...   \n",
       "2    78LjdAAw0wA                  100K Channel Update + AMA Stream!   \n",
       "3    hO_YKK_0Qck  Uber Driver to Machine Learning Engineer in 9 ...   \n",
       "4    uXLnbdHMf8w          Why I'm Starting Data Science Over Again.   \n",
       "5    Xgg7dIKys9E  Interview with the Director of AI Research @ N...   \n",
       "..           ...                                                ...   \n",
       "219  FBgs-BSTIJE                    Demystifying Data Science Roles   \n",
       "220  Yr5T3T4tq-g  Most Data Science Hopefuls Overlook This Impor...   \n",
       "221  j-Z-je6K4Yg                   IT'S NOT TOO LATE TO LEARN CODE!   \n",
       "222  5jntoZX-Tc8  NASA Physicist Turned Data Scientist (Tim Bowl...   \n",
       "223  5p73cIRYCZg                     ProjectDemoCSC478_UFCFightData   \n",
       "\n",
       "    Video pub­lish time  Com­ments ad­ded  Shares  Dis­likes  Likes  \\\n",
       "1           May 8, 2020               907    9583        942  46903   \n",
       "2          Nov 12, 2020               412       4          4    130   \n",
       "3          Jul 16, 2020               402     152         15    881   \n",
       "4          Aug 29, 2020               375     367         22   2622   \n",
       "5           Aug 5, 2020               329     118         15    590   \n",
       "..                  ...               ...     ...        ...    ...   \n",
       "219        Nov 30, 2018                 3       5          1     48   \n",
       "220        May 25, 2019                 3       0          0     44   \n",
       "221        Dec 18, 2018                 3       1          0     35   \n",
       "222         May 5, 2019                 2       5          0     38   \n",
       "223         Jun 6, 2017                 0       2          0      1   \n",
       "\n",
       "     Sub­scribers lost  Sub­scribers gained  RPM (USD)  CPM (USD)  \\\n",
       "1                  451                46904      6.353     12.835   \n",
       "2                   15                   12      2.668      6.259   \n",
       "3                    9                  198      9.516     11.695   \n",
       "4                   40                 1957      3.143      7.943   \n",
       "5                   11                  161      2.973      7.425   \n",
       "..                 ...                  ...        ...        ...   \n",
       "219                  1                    8      5.218     16.232   \n",
       "220                  0                    5      3.374     15.596   \n",
       "221                  0                    7      3.784     12.590   \n",
       "222                  0                    3      2.651     12.206   \n",
       "223                  0                    0      0.050        NaN   \n",
       "\n",
       "     Av­er­age per­cent­age viewed (%) Av­er­age view dur­a­tion    Views  \\\n",
       "1                                36.65                   0:03:09  1253559   \n",
       "2                                 6.26                   0:05:14     2291   \n",
       "3                                15.12                   0:10:21    21350   \n",
       "4                                33.41                   0:02:36    49564   \n",
       "5                                 9.55                   0:04:37    13429   \n",
       "..                                 ...                       ...      ...   \n",
       "219                              55.55                   0:03:28      978   \n",
       "220                              58.62                   0:02:06      548   \n",
       "221                              60.52                   0:01:52      721   \n",
       "222                              16.93                   0:03:09     1094   \n",
       "223                               8.79                   0:01:04       60   \n",
       "\n",
       "     Watch time (hours)  Sub­scribers  Your es­tim­ated rev­en­ue (USD)  \\\n",
       "1            65850.7042         46453                          7959.533   \n",
       "2              200.2966            -3                             6.113   \n",
       "3             3687.3387           189                           202.963   \n",
       "4             2148.3110          1917                           155.779   \n",
       "5             1034.3945           150                            39.920   \n",
       "..                  ...           ...                               ...   \n",
       "219             56.5930             7                             5.103   \n",
       "220             19.2752             5                             1.849   \n",
       "221             22.5450             7                             2.728   \n",
       "222             57.6363             3                             2.900   \n",
       "223              1.0684             0                             0.003   \n",
       "\n",
       "     Im­pres­sions  Im­pres­sions click-through rate (%)  \n",
       "1         26498799                                  3.14  \n",
       "2           188318                                  0.72  \n",
       "3           442334                                  2.53  \n",
       "4           521185                                  4.01  \n",
       "5           210876                                  3.38  \n",
       "..             ...                                   ...  \n",
       "219          26202                                  2.24  \n",
       "220          21780                                  1.61  \n",
       "221          18635                                  2.65  \n",
       "222          34642                                  1.99  \n",
       "223            365                                 11.51  \n",
       "\n",
       "[223 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_sub = pd.read_csv(\"./data/Aggregated_Metrics_By_Video.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

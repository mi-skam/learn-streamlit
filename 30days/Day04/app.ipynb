{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30days challenge\n",
    "## Day04\n",
    "\n",
    "We follow this [video](https://www.youtube.com/watch?v=Yk-unX4KnV4) *Data Science Portfolio Project From Scratch | Building a YouTube Data Dashboard with Streamlit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('app.py'):\n",
    "  os.remove('app.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  ON_COLAB = True\n",
    "except Exception:\n",
    "  ON_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "try:\n",
    "  import google.colab\n",
    "  ON_COLAB = True\n",
    "except Exception:\n",
    "  ON_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data. Let's start by loading the csv's\n",
    "\n",
    "The interesting data points are:\n",
    "- Video\n",
    "- Title\n",
    "- Video publish Time\n",
    "- Comments added\n",
    "- Shares\n",
    "- Likes / Dislikes\n",
    "- Subscribers lost / gained\n",
    "- RPM / CPM (US Dollar)\n",
    "- Average viewed / view duration / Views\n",
    "- Watch time (hours)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "if not ON_COLAB:\n",
    "  data['df_agg'] = pd.read_csv('./data/Aggregated_Metrics_By_Video.csv').iloc[1:,:]\n",
    "  data['df_agg_sub'] = pd.read_csv('./data/Aggregated_Metrics_By_Country_And_Subscriber_Status.csv')\n",
    "  data['df_comments'] = pd.read_csv('./data/All_Comments_Final.csv')\n",
    "  data['df_time'] = pd.read_csv('./data/Video_Performance_Over_Time.csv')\n",
    "else:\n",
    "  data['df_agg'] = pd.read_csv_url('https://raw.githubusercontent.com/mi-skam/learn-streamlit/main/30days/Day04/data/Aggregated_Metrics_By_Video.csv').iloc[1:,:]\n",
    "  data['df_agg_sub'] = pd.read_csv_url('https://raw.githubusercontent.com/mi-skam/learn-streamlit/main/30days/Day04/data/Aggregated_Metrics_By_Country_And_Subscriber_Status.csv')\n",
    "  data['df_comments'] = pd.read_csv_url('https://raw.githubusercontent.com/mi-skam/learn-streamlit/main/30days/Day04/data/All_Comments_Final.csv')\n",
    "  data['df_time'] = pd.read_csv_url('https://raw.githubusercontent.com/mi-skam/learn-streamlit/main/30days/Day04/data/Video_Performance_Over_Time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "@st.cache_resource\n",
    "def prepare_data():\n",
    "  # load_data\n",
    "  \n",
    "  data['df_agg'].columns = ['Video','Video title','Video publish time','Comments added','Shares','Dislikes','Likes',\n",
    "                       'Subscribers lost','Subscribers gained','RPM(USD)','CPM(USD)','Average % viewed','Average view duration',\n",
    "                       'Views','Watch time (hours)','Subscribers','Your estimated revenue (USD)','Impressions','Impressions ctr(%)']\n",
    "  data['df_agg']['Video publish time'] = pd.to_datetime(data['df_agg']['Video publish time'], format=\"mixed\")\n",
    "  data['df_agg']['Average view duration'] = data['df_agg']['Average view duration'].apply(lambda x: datetime.strptime(x,'%H:%M:%S'))\n",
    "  data['df_agg']['Avg_duration_sec'] = data['df_agg']['Average view duration'].apply(lambda x: x.second + x.minute*60 + x.hour*3600)\n",
    "  data['df_agg']['Engagement_ratio'] =  (data['df_agg']['Comments added'] + data['df_agg']['Shares'] + data['df_agg']['Dislikes'] + data['df_agg']['Likes']) /data['df_agg'].Views\n",
    "  data['df_agg']['Views / sub gained'] = data['df_agg']['Views'] / data['df_agg']['Subscribers gained']\n",
    "  data['df_agg'].sort_values('Video publish time', ascending = False, inplace = True)    \n",
    "  data['df_time']['Date'] = pd.to_datetime(data['df_time']['Date'],format=\"mixed\")\n",
    "  \n",
    "  return data['df_agg'], data['df_agg_sub'], data['df_comments'], data['df_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "df_agg, df_agg_sub, df_comments, df_data = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "sidebar = st.sidebar.selectbox(\"Aggregate or Individual Videos analysis\", (\"Aggregate\", \"Individual\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ON_COLAB:\n",
    "  # Run locally\n",
    "  !streamlit run app.py &> ./streamlit.log\n",
    "else:\n",
    "  # Run on google colab\n",
    "  import urllib\n",
    "\n",
    "  !npm install localtunnel\n",
    "\n",
    "  print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
    "  !streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
